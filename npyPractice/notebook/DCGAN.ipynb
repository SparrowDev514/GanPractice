{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hheK-MQ9ShhX"
   },
   "source": [
    "# Deep Convolutional GAN (DCGAN) with NPY files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4070,
     "status": "ok",
     "timestamp": 1586044647522,
     "user": {
      "displayName": "siny",
      "photoUrl": "https://lh4.googleusercontent.com/-z-yylDZd2Yg/AAAAAAAAAAI/AAAAAAAACjA/q4yWhDBXG5Y/s64/photo.jpg",
      "userId": "06524332640654327564"
     },
     "user_tz": -540
    },
    "id": "xLwecdqMe-Tj",
    "outputId": "786f3f99-0b60-4efc-913b-a45b80151ca6"
   },
   "outputs": [],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Select the Runtime → \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
    "  print('and then re-execute this cell.')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "source": [
    "## 環境変数を設定"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 引き継ぐ学習回数の設定（初回/二回目以降）\n",
    "# 画像サイズの設定\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0_VTxQLMxbE-"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Activation, BatchNormalization, Dense, Dropout, Flatten, Reshape\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
    "#モデルの可視化\n",
    "from tensorflow.python.keras.utils.vis_utils import plot_model\n",
    "\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import load_model\t\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LDG--zGUzpG_"
   },
   "outputs": [],
   "source": [
    "# 入力画像サイズを変更できる様にする\n",
    "img_rows = 128\n",
    "img_cols = 128\n",
    "channels = 3\n",
    "\n",
    "# 入力画像の形状（64 x 64 x 3) //カラー画像\n",
    "img_shape = (img_rows, img_cols, channels)\n",
    "\n",
    "# noiseベクトルサイズ（生成器へのINPUT)\n",
    "z_dim = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LvhCnCysz2S9"
   },
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LSowNWaKz2-D"
   },
   "outputs": [],
   "source": [
    "def build_generator(z_dim):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # 全結合層によってnoiseベクトル(200次元）をReshapeして7x7x256 tensorに変換する\n",
    "    model.add(Dense(256 * 8 * 8, input_dim=z_dim))\n",
    "    model.add(Reshape((8, 8, 256)))\n",
    "\n",
    "    # 転置畳み込みにより8x8x256 から 16x16x128テンソルに変換\n",
    "    model.add(Conv2DTranspose(128, kernel_size=3, strides=2, padding='same'))\n",
    "\n",
    "    # バッチ正規化\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Leaky ReLU活性化\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "    # 転置畳み込みにより16x16x128 から 32x32x64テンソルに変換\n",
    "    model.add(Conv2DTranspose(128, kernel_size=3, strides=2, padding='same'))\n",
    "\n",
    "    # バッチ正規化\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Leaky ReLU活性化\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "    # 転置畳み込みにより32x32x64 から32x32x32 テンソルに変換\n",
    "    model.add(Conv2DTranspose(64, kernel_size=3, strides=1, padding='same'))\n",
    "    \n",
    "    # 転置畳み込みにより32x32x32 から64x64x64 テンソルに変換\n",
    "    model.add(Conv2DTranspose(64, kernel_size=3, strides=2, padding='same'))\n",
    "\n",
    "    # バッチ正規化\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Leaky ReLU活性化\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "    # Transposed convolution layer, from 32x32x32 to 64x64x3 tensor\n",
    "    #入力画像サイズを変更できる様にする 32*strides→出力サイズ\n",
    "    model.add(Conv2DTranspose(3, kernel_size=3, strides=2, padding='same'))\n",
    "\n",
    "    # tanh活性化を適用して出力（最終層だけはバッチ正規化はしない）\n",
    "    model.add(Activation('tanh'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1829,
     "status": "ok",
     "timestamp": 1586042346775,
     "user": {
      "displayName": "siny",
      "photoUrl": "https://lh4.googleusercontent.com/-z-yylDZd2Yg/AAAAAAAAAAI/AAAAAAAACjA/q4yWhDBXG5Y/s64/photo.jpg",
      "userId": "06524332640654327564"
     },
     "user_tz": -540
    },
    "id": "6K27AgrXz0Ni",
    "outputId": "923c8e78-bbf3-4d94-f3a5-92f9ea24f790"
   },
   "outputs": [],
   "source": [
    "build_model = build_generator(z_dim)\n",
    "\n",
    "plot_model(build_model, to_file=\"DCGAB_build_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HRvWfVOY25pk"
   },
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HCYN6_y1xaDg"
   },
   "outputs": [],
   "source": [
    "def build_discriminator(img_shape):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # 64x64x3(入力画像) を32x32x32のテンソルにする畳み込み層\n",
    "    model.add(\n",
    "        Conv2D(32,\n",
    "               kernel_size=3,\n",
    "               strides=2,\n",
    "               input_shape=img_shape,\n",
    "               padding='same')) #padding=sameにすると、入力の大きさをstridesの大きさで単純に割ったもの(28/2=14)が出力の大きさになる\n",
    "\n",
    "    # Leaky ReLUによる活性化(最初の層にはバッチ正規化は適用しない)\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "    # 32x32x32 を16x16x64のテンソルにする畳み込み層\n",
    "    model.add(\n",
    "        Conv2D(64,\n",
    "               kernel_size=3,\n",
    "               strides=2,\n",
    "               input_shape=img_shape,\n",
    "               padding='same'))\n",
    "\n",
    "    # バッチ正規化\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Leaky ReLUによる活性化\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "    # 16x16x64 を8x8x128のテンソルにする畳み込み層\n",
    "    model.add(\n",
    "        Conv2D(128,\n",
    "               kernel_size=3,\n",
    "               strides=2,\n",
    "               input_shape=img_shape,\n",
    "               padding='same'))\n",
    "\n",
    "    # バッチ正規化\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Leaky ReLU活性化\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "    # シグモイド関数で出力（０～１）\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1475,
     "status": "ok",
     "timestamp": 1586042353755,
     "user": {
      "displayName": "siny",
      "photoUrl": "https://lh4.googleusercontent.com/-z-yylDZd2Yg/AAAAAAAAAAI/AAAAAAAACjA/q4yWhDBXG5Y/s64/photo.jpg",
      "userId": "06524332640654327564"
     },
     "user_tz": -540
    },
    "id": "L2PvulUHxTMJ",
    "outputId": "32262a31-73ab-4799-d691-a55e71d7189e"
   },
   "outputs": [],
   "source": [
    "discriminator_model = build_discriminator(img_shape)\n",
    "\n",
    "plot_model(discriminator_model, to_file=\"DCGAB_discriminator_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "081HxAtgxPx_"
   },
   "outputs": [],
   "source": [
    "def build_gan(generator, discriminator):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # 生成器と識別機を結合\n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2019,
     "status": "ok",
     "timestamp": 1586042360090,
     "user": {
      "displayName": "siny",
      "photoUrl": "https://lh4.googleusercontent.com/-z-yylDZd2Yg/AAAAAAAAAAI/AAAAAAAACjA/q4yWhDBXG5Y/s64/photo.jpg",
      "userId": "06524332640654327564"
     },
     "user_tz": -540
    },
    "id": "JaqRVSRq4UVa",
    "outputId": "08cb7ad5-2b1b-45cd-ee46-4ea0ad874237"
   },
   "outputs": [],
   "source": [
    "discriminator = build_discriminator(img_shape)\n",
    "generator = build_generator(z_dim)\n",
    "gan_model = build_gan(generator, discriminator)\n",
    "\n",
    "plot_model(gan_model, to_file=\"DCGAB_gan_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5061,
     "status": "ok",
     "timestamp": 1586809312206,
     "user": {
      "displayName": "siny",
      "photoUrl": "https://lh4.googleusercontent.com/-z-yylDZd2Yg/AAAAAAAAAAI/AAAAAAAACjA/q4yWhDBXG5Y/s64/photo.jpg",
      "userId": "06524332640654327564"
     },
     "user_tz": -540
    },
    "id": "x_YqyzNF4V8x",
    "outputId": "e8d641cc-0c32-42cf-dd04-4a667ee83d1c"
   },
   "outputs": [],
   "source": [
    "# 識別機の生成とコンパイル\n",
    "discriminator = build_discriminator(img_shape)\n",
    "discriminator.compile(loss='binary_crossentropy',\n",
    "                      optimizer=Adam(),\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "#前回学習の重みをロード\n",
    "#初回と二回目以降を if 文で切り分けられる様にする\n",
    "discriminator.load_weights('./../../npyPractice/models/D/d_model-0.h5')\n",
    "\n",
    "# 生成器の生成\n",
    "generator = build_generator(z_dim)\n",
    "\n",
    "# 生成器の訓練時は識別機のパラメータを固定する\n",
    "discriminator.trainable = False\n",
    "\n",
    "# 識別機は固定のまま生成器を訓練するGANモデルの生成とコンパイル\n",
    "gan = build_gan(generator, discriminator)\n",
    "gan.compile(loss='binary_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9WjyePJLMyXc"
   },
   "outputs": [],
   "source": [
    "#途中までの学習済みモデルのロード\n",
    "from keras.models import load_model\n",
    "\n",
    "model_g_dir = \"./../../npyPractice/models/G\"\n",
    "model_d_dir = \"./../../npyPractice/models/D\"\n",
    "\n",
    "# generator = load_model('/content/drive/My Drive/Colab Notebooks/GAN/models/G/g_model-1499.h5')\n",
    "#初回と二回目以降を if 文で切り分けられる様にする\n",
    "generator.load_weights('./../../npyPractice/models/G/g_param-0.hdf5')\n",
    "\n",
    "\n",
    "# gan = load_model('/content/drive/My Drive/Colab Notebooks/GAN/models/D/d_model-1499.h5')\t\n",
    "#初回と二回目以降を if 文で切り分けられる様にする\n",
    "gan.load_weights('./../../npyPractice/models/G/gan_param-0.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xmnVk9Ie4bwC"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f54i-qst4ZOF"
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "accuracies = []\n",
    "iteration_checkpoints = []\n",
    "output_dir = \"./../../npyPractice/data/result\"\n",
    "model_g_dir = \"./../../npyPractice/models/G\"\n",
    "model_d_dir = \"./../../npyPractice/models/D\"\n",
    "num_of_trials = 0\n",
    "\n",
    "def train(iterations, batch_size, sample_interval):\n",
    "  # 学習するデータセットを読み込む\n",
    "  datasets = np.load(\"/Users/murakamikei/Desktop/GanPractice/npyPractice/data/result.npy\")\n",
    "\n",
    "  # ndary型に変換\n",
    "  X_train = datasets # (2000, 64, 64, 3)\n",
    "\n",
    "  # Rescale [0, 255] grayscale pixel values to [-1, 1]\n",
    "  X_train = X_train / 127.5 - 1.0\n",
    "    \n",
    "  # Labels for real images: all ones\n",
    "  real = np.ones((batch_size, 1))\n",
    "\n",
    "  # Labels for fake images: all zeros\n",
    "  fake = np.zeros((batch_size, 1))\n",
    "  print(\"check-001\")\n",
    "\n",
    "  for iteration in range(iterations):\n",
    "\n",
    "      # -------------------------\n",
    "      #  Train the Discriminator\n",
    "      # -------------------------\n",
    "      print(\"iteration=\", iteration)\n",
    "      # Get a random batch of real images\n",
    "      idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "      imgs = X_train[idx]\n",
    "       # Generate a batch of fake images\n",
    "      z = np.random.normal(0, 1, (batch_size, 100))\n",
    "      gen_imgs = generator.predict(z)\n",
    "       # Train Discriminator\n",
    "      d_loss_real = discriminator.train_on_batch(imgs, real)\n",
    "      d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n",
    "      d_loss, accuracy = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "     \n",
    "      \n",
    "      # ---------------------\n",
    "      #  Train the Generator\n",
    "      # ---------------------\n",
    "\n",
    "      # Generate a batch of fake images\n",
    "      z = np.random.normal(0, 1, (batch_size, 100))\n",
    "      gen_imgs = generator.predict(z)\n",
    "\n",
    "      # Train Generator\n",
    "      g_loss = gan.train_on_batch(z, real)\n",
    "\n",
    "      # if (iteration + 1) % sample_interval == 0:\n",
    "      if iteration % sample_interval == 0:\n",
    "          # Save losses and accuracies so they can be plotted after training\n",
    "          losses.append((d_loss, g_loss))\n",
    "          accuracies.append(100.0 * accuracy)\n",
    "          iteration_checkpoints.append(iteration + 1)\n",
    "\n",
    "          # Output training progress\n",
    "          print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" %\n",
    "                (iteration + 1, d_loss, 100.0 * accuracy, g_loss))\n",
    "\n",
    "          # Output a sample of generated image\n",
    "          sample_images(generator, iteration)\n",
    "          #識別器のモデル保存\n",
    "          d_model_file=os.path.join(model_d_dir, \"d_model-\" + str(iteration + num_of_trials) +  \".h5\")\n",
    "          d_param_file=os.path.join(model_d_dir, \"d_param-\" + str(iteration + num_of_trials) +  \".hdf5\")\n",
    "          discriminator.save(d_model_file)\t\n",
    "          discriminator.save_weights(d_param_file)\n",
    "          \n",
    "          #生成器のモデル保存\n",
    "          g_model_file=os.path.join(model_g_dir, \"g_model-\" + str(iteration + num_of_trials) +  \".h5\")\n",
    "          g_param_file=os.path.join(model_g_dir, \"g_param-\" + str(iteration + num_of_trials) +  \".hdf5\")\n",
    "          generator.save(g_model_file)\t\n",
    "          generator.save_weights(g_param_file)\n",
    "          gan_model_file=os.path.join(model_g_dir, \"gan_model-\" + str(iteration + num_of_trials) +  \".h5\")\n",
    "          gan_param_file=os.path.join(model_g_dir, \"gan_param-\" + str(iteration + num_of_trials) +  \".hdf5\")\n",
    "\n",
    "          gan.save(gan_model_file)\t\n",
    "          gan.save_weights(gan_param_file)\n",
    "          \n",
    "          \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6GKJZSJUameW"
   },
   "outputs": [],
   "source": [
    "def sample_images(generator, iteration, image_grid_rows=4, image_grid_columns=4):\n",
    "\n",
    "    # Sample random noise\n",
    "    z = np.random.normal(0, 1, (image_grid_rows * image_grid_columns, z_dim))\n",
    "\n",
    "    # Generate images from random noise\n",
    "    gen_imgs = generator.predict(z)  # (16, 64, 64, 3)\n",
    "\n",
    "    # Rescale image pixel values to [0, 1]\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "    # Set image grid\n",
    "    fig, axs = plt.subplots(image_grid_rows,\n",
    "                            image_grid_columns,\n",
    "                            figsize=(4, 4),\n",
    "                            sharey=True,\n",
    "                            sharex=True)\n",
    "    print(\"生成されている画像の枚数とサイズ\", gen_imgs.shape)\n",
    "    # print(\"gen_imgs_type=\", type(gen_imgs.shape))\n",
    "    print(\"生成されている一枚一枚の画像サイズ=\", gen_imgs[0,:,:,:].shape)\n",
    "    cnt = 0\n",
    "    for i in range(image_grid_rows):\n",
    "        for j in range(image_grid_columns):\n",
    "            # Output a grid of images\n",
    "            print(\"shape=\",gen_imgs[cnt, :, :, :].shape)\n",
    "            axs[i, j].imshow(gen_imgs[cnt, :, :, :])\n",
    "            axs[i, j].axis('off')\n",
    "            cnt += 1\n",
    "    #file保存\n",
    "    output_file = os.path.join(output_dir, 'result_' + str(iteration + num_of_trials) +'.png')\n",
    "    plt.savefig(output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12894557,
     "status": "ok",
     "timestamp": 1586326917669,
     "user": {
      "displayName": "siny",
      "photoUrl": "https://lh4.googleusercontent.com/-z-yylDZd2Yg/AAAAAAAAAAI/AAAAAAAACjA/q4yWhDBXG5Y/s64/photo.jpg",
      "userId": "06524332640654327564"
     },
     "user_tz": -540
    },
    "id": "EDH52OExaeUJ",
    "outputId": "6589c72d-a188-4c5d-a46e-122c2d4958cd",
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# Set hyperparameters\n",
    "\n",
    "batch_size = 64\n",
    "#初回と二回目以降を if 文で切り分けられる様にする\n",
    "iterations = 20000\n",
    "# iterarions =  1\n",
    "sample_interval = 500\n",
    "# sample_interval = 1\n",
    "\n",
    "# Train the DCGAN for the specified number of iterations\n",
    "train(iterations, batch_size, sample_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t25nGL9iJM1P"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNO8n7CjOyReLrQKa8MVCvs",
   "collapsed_sections": [],
   "name": "DCGAN_with_cats.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python368jvsc74a57bd0b74db3045927d4cc0cb83b42d78957f9842c9f370326e8ec4d62549a4f4e9b44",
   "display_name": "Python 3.6.8 64-bit ('npyPractice': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}