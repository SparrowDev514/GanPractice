{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hheK-MQ9ShhX"
   },
   "source": [
    "# Deep Convolutional GAN (DCGAN) with cats images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4070,
     "status": "ok",
     "timestamp": 1586044647522,
     "user": {
      "displayName": "siny",
      "photoUrl": "https://lh4.googleusercontent.com/-z-yylDZd2Yg/AAAAAAAAAAI/AAAAAAAACjA/q4yWhDBXG5Y/s64/photo.jpg",
      "userId": "06524332640654327564"
     },
     "user_tz": -540
    },
    "id": "xLwecdqMe-Tj",
    "outputId": "786f3f99-0b60-4efc-913b-a45b80151ca6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: nvidia-smi\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Select the Runtime → \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
    "  print('and then re-execute this cell.')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 664
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 55658,
     "status": "ok",
     "timestamp": 1586809240713,
     "user": {
      "displayName": "siny",
      "photoUrl": "https://lh4.googleusercontent.com/-z-yylDZd2Yg/AAAAAAAAAAI/AAAAAAAACjA/q4yWhDBXG5Y/s64/photo.jpg",
      "userId": "06524332640654327564"
     },
     "user_tz": -540
    },
    "id": "Mezf2BJBSlJc",
    "outputId": "661c8212-1ff8-4ac6-be39-6d14190c6cd2"
   },
   "outputs": [],
   "source": [
    "# !pip install TensorFlow==1.14\n",
    "#!pip install -U TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 22088,
     "status": "ok",
     "timestamp": 1586809274894,
     "user": {
      "displayName": "siny",
      "photoUrl": "https://lh4.googleusercontent.com/-z-yylDZd2Yg/AAAAAAAAAAI/AAAAAAAACjA/q4yWhDBXG5Y/s64/photo.jpg",
      "userId": "06524332640654327564"
     },
     "user_tz": -540
    },
    "id": "DdIe9Dt7Sw7l",
    "outputId": "084d1344-2535-4b20-e1b5-7ef324cf348c"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive \n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13327,
     "status": "ok",
     "timestamp": 1586038893818,
     "user": {
      "displayName": "siny",
      "photoUrl": "https://lh4.googleusercontent.com/-z-yylDZd2Yg/AAAAAAAAAAI/AAAAAAAACjA/q4yWhDBXG5Y/s64/photo.jpg",
      "userId": "06524332640654327564"
     },
     "user_tz": -540
    },
    "id": "hqiyf336xc_d",
    "outputId": "8507c918-5fa4-445e-c969-00d7a4ce3267"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     501\r\n"
     ]
    }
   ],
   "source": [
    "#ファイル数のチェック\n",
    "!ls \"./../data/cats\" | wc -w  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0_VTxQLMxbE-"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Activation, BatchNormalization, Dense, Dropout, Flatten, Reshape\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
    "#モデルの可視化\n",
    "#from tensorflow.python.keras.utils.vis_utils import plot_model\n",
    "\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import load_model\t\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LDG--zGUzpG_"
   },
   "outputs": [],
   "source": [
    "img_rows = 64\n",
    "img_cols = 64\n",
    "channels = 3\n",
    "\n",
    "# 入力画像の形状（64 x 64 x 3) //カラー画像\n",
    "img_shape = (img_rows, img_cols, channels)\n",
    "\n",
    "# noiseベクトルサイズ（生成器へのINPUT)\n",
    "z_dim = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LvhCnCysz2S9"
   },
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LSowNWaKz2-D"
   },
   "outputs": [],
   "source": [
    "def build_generator(z_dim):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    #  全結合層によってnoiseベクトル(200次元）をReshapeして7x7x256 tensorに変換する\n",
    "    model.add(Dense(256 * 8 * 8, input_dim=z_dim))\n",
    "    model.add(Reshape((8, 8, 256)))\n",
    "\n",
    "    # 転置畳み込みにより8x8x256 から 16x16x128テンソルに変換\n",
    "    model.add(Conv2DTranspose(128, kernel_size=3, strides=2, padding='same'))\n",
    "\n",
    "    # バッチ正規化\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Leaky ReLU活性化\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "    # 転置畳み込みにより16x16x128 から 32x32x64テンソルに変換\n",
    "    model.add(Conv2DTranspose(128, kernel_size=3, strides=2, padding='same'))\n",
    "\n",
    "    # バッチ正規化\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Leaky ReLU活性化\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "    # 転置畳み込みにより32x32x64 から32x32x32 テンソルに変換\n",
    "    model.add(Conv2DTranspose(64, kernel_size=3, strides=1, padding='same'))\n",
    "\n",
    "    # バッチ正規化\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Leaky ReLU活性化\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "    # Transposed convolution layer, from 32x32x32 to 64x64x3 tensor\n",
    "    model.add(Conv2DTranspose(3, kernel_size=3, strides=2, padding='same'))\n",
    "\n",
    "    # tanh活性化を適用して出力（最終層だけはバッチ正規化はしない）\n",
    "    model.add(Activation('tanh'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1829,
     "status": "ok",
     "timestamp": 1586042346775,
     "user": {
      "displayName": "siny",
      "photoUrl": "https://lh4.googleusercontent.com/-z-yylDZd2Yg/AAAAAAAAAAI/AAAAAAAACjA/q4yWhDBXG5Y/s64/photo.jpg",
      "userId": "06524332640654327564"
     },
     "user_tz": -540
    },
    "id": "6K27AgrXz0Ni",
    "outputId": "923c8e78-bbf3-4d94-f3a5-92f9ea24f790"
   },
   "outputs": [],
   "source": [
    "build_model = build_generator(z_dim)\n",
    "\n",
    "# plot_model(build_model, to_file=\"DCGAB_build_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HRvWfVOY25pk"
   },
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HCYN6_y1xaDg"
   },
   "outputs": [],
   "source": [
    "def build_discriminator(img_shape):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # 64x64x3(入力画像) を32x32x32のテンソルにする畳み込み層\n",
    "    model.add(\n",
    "        Conv2D(32,\n",
    "               kernel_size=3,\n",
    "               strides=2,\n",
    "               input_shape=img_shape,\n",
    "               padding='same')) #padding=sameにすると、入力の大きさをstridesの大きさで単純に割ったもの(28/2=14)が出力の大きさになる\n",
    "\n",
    "    # Leaky ReLUによる活性化(最初の層にはバッチ正規化は適用しない)\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "    # 32x32x32 を16x16x64のテンソルにする畳み込み層\n",
    "    model.add(\n",
    "        Conv2D(64,\n",
    "               kernel_size=3,\n",
    "               strides=2,\n",
    "               input_shape=img_shape,\n",
    "               padding='same'))\n",
    "\n",
    "    # バッチ正規化\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Leaky ReLUによる活性化\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "    # 16x16x64 を8x8x128のテンソルにする畳み込み層\n",
    "    model.add(\n",
    "        Conv2D(128,\n",
    "               kernel_size=3,\n",
    "               strides=2,\n",
    "               input_shape=img_shape,\n",
    "               padding='same'))\n",
    "\n",
    "    # バッチ正規化\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Leaky ReLU活性化\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "    # シグモイド関数で出力（０～１）\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1475,
     "status": "ok",
     "timestamp": 1586042353755,
     "user": {
      "displayName": "siny",
      "photoUrl": "https://lh4.googleusercontent.com/-z-yylDZd2Yg/AAAAAAAAAAI/AAAAAAAACjA/q4yWhDBXG5Y/s64/photo.jpg",
      "userId": "06524332640654327564"
     },
     "user_tz": -540
    },
    "id": "L2PvulUHxTMJ",
    "outputId": "32262a31-73ab-4799-d691-a55e71d7189e"
   },
   "outputs": [],
   "source": [
    "discriminator_model = build_discriminator(img_shape)\n",
    "\n",
    "# plot_model(discriminator_model, to_file=\"DCGAB_discriminator_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "081HxAtgxPx_"
   },
   "outputs": [],
   "source": [
    "def build_gan(generator, discriminator):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # 生成器と識別機を結合\n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2019,
     "status": "ok",
     "timestamp": 1586042360090,
     "user": {
      "displayName": "siny",
      "photoUrl": "https://lh4.googleusercontent.com/-z-yylDZd2Yg/AAAAAAAAAAI/AAAAAAAACjA/q4yWhDBXG5Y/s64/photo.jpg",
      "userId": "06524332640654327564"
     },
     "user_tz": -540
    },
    "id": "JaqRVSRq4UVa",
    "outputId": "08cb7ad5-2b1b-45cd-ee46-4ea0ad874237"
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "`pydot` failed to call GraphViz.Please install GraphViz (https://www.graphviz.org/) and ensure that its executables are in the $PATH.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/npyPractice/lib/python3.6/site-packages/pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, prog, format, encoding)\u001b[0m\n\u001b[1;32m   1914\u001b[0m                 \u001b[0marguments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1915\u001b[0;31m                 \u001b[0mworking_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtmp_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1916\u001b[0m             )\n",
      "\u001b[0;32m~/opt/anaconda3/envs/npyPractice/lib/python3.6/site-packages/pydot.py\u001b[0m in \u001b[0;36mcall_graphviz\u001b[0;34m(program, arguments, working_dir, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mstdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     )\n",
      "\u001b[0;32m~/opt/anaconda3/envs/npyPractice/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors)\u001b[0m\n\u001b[1;32m    728\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    730\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/npyPractice/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1363\u001b[0m                             \u001b[0merr_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1364\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1365\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dot': 'dot'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/npyPractice/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# to check the pydot/graphviz installation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/npyPractice/lib/python3.6/site-packages/pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, prog, format, encoding)\u001b[0m\n\u001b[1;32m   1921\u001b[0m                     prog=prog)\n\u001b[0;32m-> 1922\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1923\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] \"dot\" not found in path.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-294afe835f5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgan_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_gan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgan_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"DCGAB_gan_model.png\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/npyPractice/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[0;34m(model, to_file, show_shapes, show_layer_names, rankdir, expand_nested, dpi)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \"\"\"\n\u001b[1;32m    239\u001b[0m     dot = model_to_dot(model, show_shapes, show_layer_names, rankdir,\n\u001b[0;32m--> 240\u001b[0;31m                        expand_nested, dpi)\n\u001b[0m\u001b[1;32m    241\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/npyPractice/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[0;34m(model, show_shapes, show_layer_names, rankdir, expand_nested, dpi, subgraph)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0m_check_pydot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msubgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dashed'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/npyPractice/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         raise OSError(\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0;34m'`pydot` failed to call GraphViz.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0;34m'Please install GraphViz (https://www.graphviz.org/) '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             'and ensure that its executables are in the $PATH.')\n",
      "\u001b[0;31mOSError\u001b[0m: `pydot` failed to call GraphViz.Please install GraphViz (https://www.graphviz.org/) and ensure that its executables are in the $PATH."
     ]
    }
   ],
   "source": [
    "discriminator = build_discriminator(img_shape)\n",
    "generator = build_generator(z_dim)\n",
    "gan_model = build_gan(generator, discriminator)\n",
    "\n",
    "# plot_model(gan_model, to_file=\"DCGAB_gan_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5061,
     "status": "ok",
     "timestamp": 1586809312206,
     "user": {
      "displayName": "siny",
      "photoUrl": "https://lh4.googleusercontent.com/-z-yylDZd2Yg/AAAAAAAAAAI/AAAAAAAACjA/q4yWhDBXG5Y/s64/photo.jpg",
      "userId": "06524332640654327564"
     },
     "user_tz": -540
    },
    "id": "x_YqyzNF4V8x",
    "outputId": "e8d641cc-0c32-42cf-dd04-4a667ee83d1c"
   },
   "outputs": [],
   "source": [
    "# 識別機の生成とコンパイル\n",
    "discriminator = build_discriminator(img_shape)\n",
    "discriminator.compile(loss='binary_crossentropy',\n",
    "                      optimizer=Adam(),\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "#前回学習の重みをロード\n",
    "discriminator.load_weights('./../../npyPractice/models/D/d_model-0.h5')\n",
    "\n",
    "\n",
    "# 生成器の生成\n",
    "generator = build_generator(z_dim)\n",
    "\n",
    "# 生成器の訓練時は識別機のパラメータを固定する\n",
    "discriminator.trainable = False\n",
    "\n",
    "# 識別機は固定のまま生成器を訓練するGANモデルの生成とコンパイル\n",
    "gan = build_gan(generator, discriminator)\n",
    "gan.compile(loss='binary_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9WjyePJLMyXc"
   },
   "outputs": [],
   "source": [
    "#途中までの学習済みモデルのロード\n",
    "from keras.models import load_model\n",
    "\n",
    "model_g_dir = \"./../../npyPractice/models/G\"\n",
    "model_d_dir = \"./../../npyPractice/models/D\"\n",
    "\n",
    "#generator = load_model('/content/drive/My Drive/Colab Notebooks/GAN/models/G/g_model-2499.h5')\n",
    "generator.load_weights('./../../npyPractice/models/G/g_param-0.hdf5')\n",
    "\n",
    "\n",
    "#gan = load_model('/content/drive/My Drive/Colab Notebooks/GAN/models/D/d_model-2499.h5')\t\n",
    "gan.load_weights('./../../npyPractice/models/G/gan_param-0.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "07bHTiPA1p4M"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xmnVk9Ie4bwC"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f54i-qst4ZOF"
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "accuracies = []\n",
    "iteration_checkpoints = []\n",
    "train_dir = \"./../../npyPractice/data/cats\"\n",
    "output_dir = \"./../../npyPractice/data/result\"\n",
    "model_g_dir = \"./../../npyPractice/models/G\"\n",
    "model_d_dir = \"./../../npyPractice/models/D\"\n",
    "height = 64\n",
    "width = 64\n",
    "num_of_trials = 50490\n",
    "\n",
    "\n",
    "def train(iterations, batch_size, sample_interval, files):\n",
    "  arrlist = []\n",
    "  for i, imgfile in enumerate(files):\n",
    "    img = load_img(imgfile, target_size=(height, width))    # 画像ファイルの読み込み\n",
    "    array = img_to_array(img)    # 画像ファイルのnumpy化\n",
    "    arrlist.append(array)    # numpy型データをリストに追加\n",
    "    print(\"ファイルINDEX＝\", i)\n",
    "  # ndary型に変換\n",
    "  X_train = np.array(arrlist)   # (2000, 64, 64, 3)\n",
    "\n",
    "  # Rescale [0, 255] grayscale pixel values to [-1, 1]\n",
    "  X_train = X_train / 127.5 - 1.0\n",
    "    \n",
    "\n",
    "  # Labels for real images: all ones\n",
    "  real = np.ones((batch_size, 1))\n",
    "\n",
    "  # Labels for fake images: all zeros\n",
    "  fake = np.zeros((batch_size, 1))\n",
    "  print(\"check-001\")\n",
    "\n",
    "  for iteration in range(iterations):\n",
    "\n",
    "      # -------------------------\n",
    "      #  Train the Discriminator\n",
    "      # -------------------------\n",
    "      print(\"iteration=\", iteration)\n",
    "\n",
    "      # Get a random batch of real images\n",
    "      idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "      imgs = X_train[idx]\n",
    "       # Generate a batch of fake images\n",
    "      z = np.random.normal(0, 1, (batch_size, 100))\n",
    "      gen_imgs = generator.predict(z)\n",
    "       # Train Discriminator\n",
    " \n",
    "\n",
    "      d_loss_real = discriminator.train_on_batch(imgs, real)\n",
    "      d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n",
    "      d_loss, accuracy = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "     \n",
    "      \n",
    "      # ---------------------\n",
    "      #  Train the Generator\n",
    "      # ---------------------\n",
    "\n",
    "      # Generate a batch of fake images\n",
    "      z = np.random.normal(0, 1, (batch_size, 100))\n",
    "      gen_imgs = generator.predict(z)\n",
    "\n",
    "      # Train Generator\n",
    "      g_loss = gan.train_on_batch(z, real)\n",
    "\n",
    "      if (iteration + 1) % sample_interval == 0:\n",
    "\n",
    "          # Save losses and accuracies so they can be plotted after training\n",
    "          losses.append((d_loss, g_loss))\n",
    "          accuracies.append(100.0 * accuracy)\n",
    "          iteration_checkpoints.append(iteration + 1)\n",
    "\n",
    "          # Output training progress\n",
    "          print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" %\n",
    "                (iteration + 1, d_loss, 100.0 * accuracy, g_loss))\n",
    "\n",
    "          # Output a sample of generated image\n",
    "          sample_images(generator, iteration)\n",
    "          #識別器のモデル保存\n",
    "          d_model_file=os.path.join(model_d_dir, \"d_model-\" + str(iteration + num_of_trials) +  \".h5\")\n",
    "          d_param_file=os.path.join(model_d_dir, \"d_param-\" + str(iteration + num_of_trials) +  \".hdf5\")\n",
    "          discriminator.save(d_model_file)\t\n",
    "          discriminator.save_weights(d_param_file)\n",
    "          \n",
    "          #生成器のモデル保存\n",
    "          g_model_file=os.path.join(model_g_dir, \"g_model-\" + str(iteration + num_of_trials) +  \".h5\")\n",
    "          g_param_file=os.path.join(model_g_dir, \"g_param-\" + str(iteration + num_of_trials) +  \".hdf5\")\n",
    "          generator.save(g_model_file)\t\n",
    "          generator.save_weights(g_param_file)\n",
    "          gan_model_file=os.path.join(model_g_dir, \"gan_model-\" + str(iteration + num_of_trials) +  \".h5\")\n",
    "          gan_param_file=os.path.join(model_g_dir, \"gan_param-\" + str(iteration + num_of_trials) +  \".hdf5\")\n",
    "\n",
    "          gan.save(gan_model_file)\t\n",
    "          gan.save_weights(gan_param_file)\n",
    "          \n",
    "          \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6GKJZSJUameW"
   },
   "outputs": [],
   "source": [
    "def sample_images(generator, iteration, image_grid_rows=4, image_grid_columns=4):\n",
    "\n",
    "    # Sample random noise\n",
    "    z = np.random.normal(0, 1, (image_grid_rows * image_grid_columns, z_dim))\n",
    "\n",
    "    # Generate images from random noise\n",
    "    gen_imgs = generator.predict(z)  # (16, 64, 64, 3)\n",
    "\n",
    "    # Rescale image pixel values to [0, 1]\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "    # Set image grid\n",
    "    fig, axs = plt.subplots(image_grid_rows,\n",
    "                            image_grid_columns,\n",
    "                            figsize=(4, 4),\n",
    "                            sharey=True,\n",
    "                            sharex=True)\n",
    "    #print(\"gen_imgs_shape=\", gen_imgs.shape)\n",
    "    #print(\"gen_imgs_type=\", type(gen_imgs.shape))\n",
    "    #print(\"gen_imgs_shape2=\", gen_imgs[0,:,:,:].shape)\n",
    "    cnt = 0\n",
    "    for i in range(image_grid_rows):\n",
    "        for j in range(image_grid_columns):\n",
    "            # Output a grid of images\n",
    "            #print(\"shape=\",gen_imgs[cnt, :, :, :].shape)\n",
    "            axs[i, j].imshow(gen_imgs[cnt, :, :, :])\n",
    "            axs[i, j].axis('off')\n",
    "            cnt += 1\n",
    "    #file保存\n",
    "    output_file = os.path.join(output_dir, 'result_' + str(iteration + num_of_trials) +'.png')\n",
    "    plt.savefig(output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12894557,
     "status": "ok",
     "timestamp": 1586326917669,
     "user": {
      "displayName": "siny",
      "photoUrl": "https://lh4.googleusercontent.com/-z-yylDZd2Yg/AAAAAAAAAAI/AAAAAAAACjA/q4yWhDBXG5Y/s64/photo.jpg",
      "userId": "06524332640654327564"
     },
     "user_tz": -540
    },
    "id": "EDH52OExaeUJ",
    "outputId": "6589c72d-a188-4c5d-a46e-122c2d4958cd"
   },
   "outputs": [],
   "source": [
    "files = glob.glob(\"./../../npyPractice/data/cats/*.jpg\")\n",
    "# Set hyperparameters\n",
    "iterations = 5000\n",
    "batch_size =64\n",
    "sample_interval = 1\n",
    "\n",
    "# Train the DCGAN for the specified number of iterations\n",
    "train(iterations, batch_size, sample_interval, files[0:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t25nGL9iJM1P"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "11PeEjJ4bfYS"
   },
   "outputs": [],
   "source": [
    "  "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNO8n7CjOyReLrQKa8MVCvs",
   "collapsed_sections": [],
   "name": "DCGAN_with_cats.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
